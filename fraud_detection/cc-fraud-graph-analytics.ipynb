{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport math\nimport pandas as pd\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-22T23:02:44.865379Z","iopub.execute_input":"2022-02-22T23:02:44.866064Z","iopub.status.idle":"2022-02-22T23:02:45.249487Z","shell.execute_reply.started":"2022-02-22T23:02:44.865971Z","shell.execute_reply":"2022-02-22T23:02:45.248688Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Data Exploration","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/fraud-detection/fraudTrain.csv', delimiter=',')\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\nprint('Event Rate:', np.mean(df.is_fraud))\ndisplay(df.head(3))","metadata":{"execution":{"iopub.status.busy":"2022-02-22T23:02:51.152260Z","iopub.execute_input":"2022-02-22T23:02:51.152514Z","iopub.status.idle":"2022-02-22T23:03:00.320305Z","shell.execute_reply.started":"2022-02-22T23:02:51.152489Z","shell.execute_reply":"2022-02-22T23:03:00.319282Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**The event rate is 0.5%, so the dataset is highly imbalanced, we will random pick 20% non-event observations and all event observations to do undersampling.**","metadata":{}},{"cell_type":"code","source":"train_data = df[df.is_fraud==0].sample(frac=0.2, random_state = 2).append(df[df.is_fraud==1])\nprint('Event Rate:', np.mean(train_data.is_fraud))\nprint('Event Rate Distribution:\\n', train_data.is_fraud.value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2022-02-22T23:03:09.921165Z","iopub.execute_input":"2022-02-22T23:03:09.921739Z","iopub.status.idle":"2022-02-22T23:03:10.896077Z","shell.execute_reply.started":"2022-02-22T23:03:09.921699Z","shell.execute_reply":"2022-02-22T23:03:10.895379Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Prepare Graph Data","metadata":{}},{"cell_type":"code","source":"def build_graph_bipartite(df_input, graph_type=nx.Graph()):\n    df = df_input.copy()\n    mapping = {x: node_id for node_id, x in enumerate(set(df['cc_num'].values.tolist()+\n                                                          df['merchant'].values.tolist()))}\n    df['from'] = df['cc_num'].apply(lambda x: mapping[x])\n    df['to'] = df['merchant'].apply(lambda x: mapping[x])\n    df = df[['from','to','amt','is_fraud']].groupby(['from','to']).agg({'is_fraud':'sum','amt':'sum'}).reset_index()\n    df['is_fraud'] = df['is_fraud'].apply(lambda x: 1 if x>0 else 0)\n    \n    G = nx.from_edgelist(df[['from','to']].values, create_using = graph_type)\n    \n    nx.set_node_attributes(G, {x:1 for x in df['from'].unique()}, 'bipartite')\n    nx.set_node_attributes(G, {x:2 for x in df['to'].unique()}, 'bipartite')\n    \n    nx.set_edge_attributes(G, \n                          {(int(x['from']), int(x['to'])): x['is_fraud'] for idx, x in df[['from','to','is_fraud']].iterrows()},\n                          'label')\n    nx.set_edge_attributes(G, \n                          {(int(x['from']), int(x['to'])): x['amt'] for idx, x in df[['from','to','amt']].iterrows()},\n                          'weight')\n    return(G)","metadata":{"execution":{"iopub.status.busy":"2022-02-22T23:03:15.643832Z","iopub.execute_input":"2022-02-22T23:03:15.644381Z","iopub.status.idle":"2022-02-22T23:03:15.654078Z","shell.execute_reply.started":"2022-02-22T23:03:15.644354Z","shell.execute_reply":"2022-02-22T23:03:15.652757Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def build_graph_tripartite(df_input, graph_type=nx.Graph()):\n    df = df_input.copy()\n    mapping = {x: node_id for node_id, x in enumerate(set(df.index.values.tolist() + \n                                                          df['cc_num'].values.tolist()+\n                                                          df['merchant'].values.tolist()))}\n    \n    df['in_node'] = df['cc_num'].apply(lambda x: mapping[x])\n    df['out_node'] = df['merchant'].apply(lambda x: mapping[x])\n       \n    G = nx.from_edgelist([(x['in_node'], mapping[idx]) for idx, x in df.iterrows()] +\n                         [(x['out_node'], mapping[idx]) for idx, x in df.iterrows()],\n                         create_using = graph_type)\n    \n    nx.set_node_attributes(G, {x['in_node']:1 for idx, x in df.iterrows()}, 'bipartite')\n    nx.set_node_attributes(G, {x['out_node']:2 for idx, x in df.iterrows()}, 'bipartite')\n    nx.set_node_attributes(G, {mapping[idx]:3 for idx, x in df.iterrows()}, 'bipartite')\n    \n    nx.set_edge_attributes(G, \n                          {(int(x['in_node']), mapping[idx]): x['is_fraud'] for idx, x in df.iterrows()},\n                          'label')\n    nx.set_edge_attributes(G, \n                          {(int(x['out_node']), mapping[idx]): x['is_fraud'] for idx, x in df.iterrows()},\n                          'label')\n   \n    nx.set_edge_attributes(G, \n                          {(int(x['in_node']), mapping[idx]): x['amt'] for idx, x in df.iterrows()},\n                          'weight')\n    nx.set_edge_attributes(G, \n                          {(int(x['out_node']), mapping[idx]): x['amt'] for idx, x in df.iterrows()},\n                          'weight')\n    \n    return(G)","metadata":{"execution":{"iopub.status.busy":"2022-02-22T23:03:18.813893Z","iopub.execute_input":"2022-02-22T23:03:18.814148Z","iopub.status.idle":"2022-02-22T23:03:18.831057Z","shell.execute_reply.started":"2022-02-22T23:03:18.814120Z","shell.execute_reply":"2022-02-22T23:03:18.830139Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"G_bu = build_graph_bipartite(train_data, nx.Graph(name=['Bipartite Undirected']))\nG_bd = build_graph_bipartite(train_data, nx.DiGraph(name=['Bipartite Directed']))\nG_tu = build_graph_tripartite(train_data, nx.Graph(name=['Tripartite Undirected']))\nG_td = build_graph_tripartite(train_data, nx.DiGraph(name=['Tripartite Directed']))","metadata":{"execution":{"iopub.status.busy":"2022-02-22T23:03:21.510644Z","iopub.execute_input":"2022-02-22T23:03:21.511016Z","iopub.status.idle":"2022-02-22T23:08:15.865265Z","shell.execute_reply.started":"2022-02-22T23:03:21.510987Z","shell.execute_reply":"2022-02-22T23:08:15.864374Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from networkx.algorithms import bipartite\nbipartite.is_bipartite(G_bu)","metadata":{"execution":{"iopub.status.busy":"2022-02-22T23:10:42.570995Z","iopub.execute_input":"2022-02-22T23:10:42.571211Z","iopub.status.idle":"2022-02-22T23:10:42.684994Z","shell.execute_reply.started":"2022-02-22T23:10:42.571188Z","shell.execute_reply":"2022-02-22T23:10:42.684282Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(nx.info(G_bu))\nprint('==========================')\nprint(nx.info(G_tu))","metadata":{"execution":{"iopub.status.busy":"2022-02-22T23:10:44.187614Z","iopub.execute_input":"2022-02-22T23:10:44.187877Z","iopub.status.idle":"2022-02-22T23:10:44.354546Z","shell.execute_reply.started":"2022-02-22T23:10:44.187848Z","shell.execute_reply":"2022-02-22T23:10:44.353945Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Node Degree Distribution**\n\nFrom the below plot we can see, the bipartite graph has a more variegated distribution, with a peak of around 300. While tripartite graph has a peak of degree 2.","metadata":{}},{"cell_type":"code","source":"for G in [G_bu, G_tu]:\n    plt.figure(figsize = (10,10))\n    degrees = pd.Series(\n        {\n            k:v for k,v in nx.degree(G)\n        }\n    )\n    degrees.plot.hist()\n    plt.yscale(\"log\")","metadata":{"execution":{"iopub.status.busy":"2022-02-22T23:11:06.044568Z","iopub.execute_input":"2022-02-22T23:11:06.044950Z","iopub.status.idle":"2022-02-22T23:11:07.686134Z","shell.execute_reply.started":"2022-02-22T23:11:06.044920Z","shell.execute_reply":"2022-02-22T23:11:07.685047Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Edge Weight Distribution**\n\nFrom the below plot, the distribution is slightly shifted to the right (right-skewed) when compared to the tripartite where the transaction nodes are more pronounced.","metadata":{}},{"cell_type":"code","source":"for G in [G_bu, G_tu]:\n    allEdgesWeights = pd.Series({\n        (d[0], d[1]): d[2]['weight'] for d in G.edges(data=True)\n    })\n    np.quantile(allEdgesWeights.values, [0.1, 0.5, 0.7, 0.9, 1])\n    quant_dist = np.quantile(allEdgesWeights.values, [0.1, 0.5, 0.7, 0.9])\n    allEdgesWeightsFiltered = pd.Series({\n        (d[0], d[1]): d[2]['weight'] for d in G.edges(data=True) if d[2]['weight'] < quant_dist[-1]\n    })\n    plt.figure(figsize = (10,10))\n    allEdgesWeightsFiltered.plot.hist(bins=40)\n    plt.yscale('log')","metadata":{"execution":{"iopub.status.busy":"2022-02-22T23:18:18.384947Z","iopub.execute_input":"2022-02-22T23:18:18.385182Z","iopub.status.idle":"2022-02-22T23:18:27.325946Z","shell.execute_reply.started":"2022-02-22T23:18:18.385159Z","shell.execute_reply":"2022-02-22T23:18:27.325458Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Degree Centrality**\n\nDegree Centrality is defined as the number of links incident upon a node (i.e., the number of ties that a node has). \n","metadata":{}},{"cell_type":"code","source":"for G in [G_bu, G_tu]:\n    plt.figure(figsize = (10,10))\n    degree_centrality = pd.Series(\n        {\n            k:v for k,v in nx.degree_centrality(G).items()\n        }\n    )\n    degree_centrality.plot.hist()\n    plt.yscale(\"log\")","metadata":{"execution":{"iopub.status.busy":"2022-02-22T23:41:29.016993Z","iopub.execute_input":"2022-02-22T23:41:29.017811Z","iopub.status.idle":"2022-02-22T23:41:30.385310Z","shell.execute_reply.started":"2022-02-22T23:41:29.017719Z","shell.execute_reply":"2022-02-22T23:41:30.384210Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"**Betweenness Centrality**\n\nIt measures the number of shortest paths that pass through a given node, providing and intuition about how central that node is for message passing within the network.","metadata":{}},{"cell_type":"code","source":"for G in [G_bu, G_tu]:\n    plt.figure(figsize = (10,10))\n    degree_centrality = pd.Series(\n        {\n            k:v for k,v in nx.betweenness_centrality(G).items()\n        }\n    )\n    degree_centrality.plot.hist()\n    plt.yscale(\"log\")","metadata":{"execution":{"iopub.status.busy":"2022-02-22T23:42:54.177297Z","iopub.execute_input":"2022-02-22T23:42:54.177540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Closeness Centrality**\n\nIt is a way of detecting nodes that are able to spread information very efficiently through a graph. the closeness centrality of a node measures its average farness (inverse distance) to all other nodes. Nodes with a high closeness score have the shortest distances to all other nodes. ","metadata":{}},{"cell_type":"code","source":"for G in [G_bu, G_tu]:\n    plt.figure(figsize = (10,10))\n    degree_centrality = pd.Series(\n        {\n            k:v for k,v in nx.closeness_centrality(G).items()\n        }\n    )\n    degree_centrality.plot.hist()\n    plt.yscale(\"log\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}